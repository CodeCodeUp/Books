# Book-Crossing 图书推荐系统项目实施计划

## 🎯 当前状态
- ✅ 已下载Book-Crossing数据集
- ✅ 已修改设计文档适配Book-Crossing数据格式  
- ✅ 已完成基础数据清洗和预处理
- ✅ 已整理项目架构和文件结构
- ✅ 已创建.gitignore文件
- ✅ 已完成用户数据处理和分析

## 📁 项目架构
```
Books/
├── data/              # 原始数据
├── processed_data/    # 清洗后数据 ✅
├── scripts/          # Python脚本 ✅  
├── docs/             # 文档文件 ✅
└── .gitignore        # Git忽略文件 ✅
```

## 📋 下一步详细计划（按优先级排序）

### 阶段一：数据预处理与验证（1-2周）🔄 进行中

#### ✅ 第1步：数据下载与格式验证
```bash
# 成功下载Book-Crossing数据集
python download_book_crossing.py
```
**完成状态**：
- ✅ 成功下载BX-CSV-Dump.zip
- ✅ 解压得到3个CSV文件（评分、图书、用户）
- ✅ 验证数据完整性

#### ✅ 第2步：数据清洗和预处理
```bash
# 运行数据清洗脚本
cd scripts && python basic_data_cleaning.py && python process_users_data.py
```
**完成状态**：
- ✅ 清洗评分数据（保留显式评分1-10分，标准化为1-5分）
- ✅ 清洗图书数据（处理CSV格式错误，标准化出版年份）
- ✅ 清洗用户数据（年龄分组，地理位置处理）
- ✅ 筛选活跃用户（有评分记录的用户）→ 7.8万用户

**已产出文件**：
```
processed_data/ratings_cleaned.csv     # 43万条评分数据
processed_data/books_metadata.csv      # 27万本图书元数据  
processed_data/users_metadata.csv      # 7.8万活跃用户数据
```

#### ✅ 第3步：数据探索性分析（EDA）
```bash
# 运行数据分析脚本
cd scripts && python analyze_book_crossing.py
```
**分析结果**：
- 原始数据：115万评分，27万图书，28万用户
- 显式评分：43万条（1-10分，标准化为1-5分）
- 活跃用户：7.8万（有评分记录的用户）
- 数据稀疏度：99.97%（推荐系统典型范围）

#### 📋 第4步：构建MySQL数据库
**状态**: 待实现
```sql
-- 创建数据库和表结构
CREATE DATABASE book_recommendation;

-- 用户表
CREATE TABLE users (
    user_id INT PRIMARY KEY,
    location VARCHAR(255),
    age INT,
    age_group VARCHAR(20)
);

-- 图书表  
CREATE TABLE books (
    book_id VARCHAR(20) PRIMARY KEY,
    title VARCHAR(500),
    author VARCHAR(200),
    year INT,
    publisher VARCHAR(200)
);

-- 评分表
CREATE TABLE ratings (
    user_id INT,
    book_id VARCHAR(20),
    rating DECIMAL(2,1),
    FOREIGN KEY (user_id) REFERENCES users(user_id),
    FOREIGN KEY (book_id) REFERENCES books(book_id)
);
```

#### 📋 第5步：数据导入和基础查询
**状态**: 待实现
```bash
# 数据导入MySQL脚本
cd scripts && python import_to_mysql.py
```
**验证查询**:
- 统计用户数、图书数、评分数
- 验证数据完整性和外键约束
- 基础统计分析查询
### 阶段二：推荐算法实现（3-4周）📋 待开始

#### 📋 第6步：用户基协同过滤实现
**实现文件**：`scripts/user_based_cf.py` 
**状态**: 待实现
```python
# 计划实现的核心功能
class UserBasedCF:
    def fit(self, ratings_data)           # 训练模型
    def predict_rating(self, user, item)  # 预测评分
    def recommend(self, user_id)          # 生成推荐
    def get_user_similarity()            # 用户相似度
```

#### 第7步：物品基协同过滤实现
**实现文件**：`scripts/item_based_cf.py`
**状态**: 待实现
```python
# 计划实现的核心功能
class ItemBasedCF:
    def fit(self, ratings_data)           # 训练模型
    def predict_rating(self, user, item)  # 预测评分  
    def recommend(self, user_id)          # 生成推荐
    def calculate_similarity()            # 物品相似度
```

#### 第8步：基于内容特征推荐实现
**实现文件**：`scripts/content_based_recommender.py`
**状态**: 待实现
```python
# 计划实现的核心功能
class BookFeatureExtractor        # 图书特征提取器
class ContentBasedRecommender     # 基于内容的推荐器
```

#### 第9步：混合推荐算法实现
**实现文件**：`scripts/hybrid_recommender.py`
**状态**: 待实现
```python
# 计划实现的功能
def hybrid_recommend(user_id, cf_weight=0.6, cb_weight=0.4)
```

### 阶段三：系统评估与优化（2-3周）

#### 第10步：推荐算法评估
**评估脚本**：`scripts/evaluate_algorithms.py`
**状态**: 待实现
- 使用sklearn实现评估指标
- Precision@10, Recall@10, F1-Score
- 交叉验证对比实验
- 生成性能对比图表

#### 第11步：算法性能优化
- 内存使用优化
- 计算速度优化
- 缓存机制实现

### 阶段四：Web系统开发（3-4周）

#### 第12步：Python算法服务开发
**实现文件**：`algorithm_service.py`
**状态**: 待实现
```python
# Flask API服务
@app.route('/recommend/<user_id>')     # 推荐接口
@app.route('/retrain')                 # 重训练接口
```

#### 第13步：SpringBoot后端开发
**核心模块**：
- RecommendController（推荐接口）
- PythonAlgorithmService（算法调用）
- UserBehaviorService（行为数据）
- BookService（图书管理）

#### 第14步：Vue前端开发
**核心页面**：
- 图书列表与搜索
- 个性化推荐页面
- 图书详情页
- 用户个人中心

#### 第15步：系统集成测试
- 前后端联调
- 算法服务集成
- 性能压力测试

### 阶段五：论文撰写与答辩准备（2-3周）

#### 第16步：实验数据收集
- 算法对比实验结果
- 系统性能测试数据
- 用户体验测试反馈

#### 第17步：论文写作
- 按论文写作指导完成各章节
- 制作系统架构图和流程图
- 整理实验结果图表

#### 第18步：答辩准备
- 制作PPT
- 准备系统演示
- 预演答辩流程

## 🛠️ 技术准备清单

### 开发环境配置
```bash
# Python环境
pip install pandas numpy scikit-learn datasets transformers flask

# Java环境  
# SpringBoot 3.x + MySQL + Redis

# 前端环境
npm install vue@next element-plus axios
```

### 项目目录结构
```
Books/
├── data/                    # 数据文件
├── algorithms/             # 推荐算法实现
│   ├── user_based_cf.py
│   ├── item_based_cf.py
│   ├── content_based_recommender.py
│   └── hybrid_recommender.py
├── evaluation/             # 算法评估
├── python_service/         # Python Flask服务
├── springboot_backend/     # SpringBoot后端
├── vue_frontend/          # Vue前端
├── docs/                  # 文档
└── experiments/           # 实验结果
```

## ⏰ 时间节点规划

| 阶段 | 时间 | 关键里程碑 |
|------|------|-----------|
| 数据处理 | 第1-2周 | 完成数据预处理和EDA |
| 算法实现 | 第3-6周 | 四种推荐算法全部实现 |
| 系统评估 | 第7-8周 | 算法评估和性能优化完成 |
| Web开发 | 第9-12周 | 完整系统开发完成 |
| 论文答辩 | 第13-15周 | 论文撰写和答辩准备 |

## 🚨 风险预警

### 潜在问题与解决方案
1. **数据量过大导致内存不足**
   - 解决：采用分批处理和稀疏矩阵存储

2. **算法计算时间过长**
   - 解决：先用小数据集验证，再逐步扩大

3. **系统集成困难**
   - 解决：先实现算法，后开发Web系统

### 备选方案
- 如果Amazon数据太大，可降采样到10万评分
- 如果计算资源不足，可简化特征维度
- 如果时间紧张，可优先保证算法实现

## 📞 下一步行动

**当前状态**: 第一阶段进行中，已完成数据下载和清洗，需要构建数据库

**立即执行**：
1. 构建MySQL数据库和表结构
2. 创建数据导入脚本 `scripts/import_to_mysql.py`
3. 验证数据库导入和基础查询功能

**本周目标**：
- 完成MySQL数据库构建
- 完成数据导入和验证
- 完成第一阶段所有任务

准备好开始构建数据库了吗？